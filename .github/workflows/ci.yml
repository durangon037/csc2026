# .github/workflows/ci.yml
# CSC Latin America 2026 - CI Pipeline
name: CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

permissions:
  contents: read

env:
  BUILD_TYPE: Release
  DEBIAN_FRONTEND: noninteractive

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # ==========================================================================
  # Build and Test (Standard)
  # ==========================================================================
  build:
    name: Build & Test
    runs-on: ubuntu-latest
    container: rootproject/root:latest

    steps:
      - uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          apt-get update
          apt-get install -y --no-install-recommends \
            cmake ninja-build git \
            python3 python3-pip
          python3 -m pip install --break-system-packages pytest pytest-cov

      - name: Configure CMake
        run: |
          cmake -B build -G Ninja \
            -DCMAKE_BUILD_TYPE=${{ env.BUILD_TYPE }} \
            -DBUILD_TESTS=ON \
            -DBUILD_BENCHMARKS=ON

      - name: Build
        run: cmake --build build -j"$(nproc)"

      - name: Run C++ Tests
        run: ctest --test-dir build --output-on-failure --verbose

      - name: Run Python Tests (only if any exist)
        if: ${{ hashFiles('tests/**/*.py') != '' }}
        run: pytest tests/ -v --tb=short

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: |
            build/analyze
            build/benchmarks
          if-no-files-found: warn
          retention-days: 7

  # ==========================================================================
  # Sanitizer Checks (ASan + UBSan)
  # ==========================================================================
  sanitizers:
    name: Sanitizers (ASan/UBSan)
    runs-on: ubuntu-latest
    container: rootproject/root:latest

    steps:
      - uses: actions/checkout@v4

      - name: Install dependencies (clang + ninja + OpenMP headers)
        run: |
          apt-get update
          apt-get install -y --no-install-recommends \
            cmake ninja-build \
            clang clang-tidy libomp-dev

      - name: Configure with Sanitizers (Clang)
        run: |
          CC=clang CXX=clang++ cmake -B build -G Ninja \
            -DCMAKE_BUILD_TYPE=Debug \
            -DENABLE_SANITIZERS=ON \
            -DBUILD_TESTS=ON \
            -DBUILD_BENCHMARKS=OFF

      - name: Build
        run: cmake --build build -j"$(nproc)"

      - name: Run Tests with Sanitizers
        env:
          ASAN_OPTIONS: abort_on_error=1:disable_coredump=0:detect_leaks=0:strict_string_checks=1
          UBSAN_OPTIONS: halt_on_error=1:print_stacktrace=1
        run: ctest --test-dir build --output-on-failure

  # ==========================================================================
  # Thread Sanitizer
  # ==========================================================================
  thread-sanitizer:
    name: Thread Sanitizer (TSan)
    runs-on: ubuntu-latest
    container: rootproject/root:latest

    steps:
      - uses: actions/checkout@v4

      - name: Install dependencies (clang + ninja + OpenMP headers)
        run: |
          apt-get update
          apt-get install -y --no-install-recommends \
            cmake ninja-build \
            clang libomp-dev

      - name: Configure with TSan (Clang)
        run: |
          CC=clang CXX=clang++ cmake -B build -G Ninja \
            -DCMAKE_BUILD_TYPE=Debug \
            -DENABLE_TSAN=ON \
            -DBUILD_TESTS=ON \
            -DBUILD_BENCHMARKS=OFF

      - name: Build
        run: cmake --build build -j"$(nproc)"

      - name: Run Tests with TSan
        env:
          TSAN_OPTIONS: abort_on_error=1
        run: ctest --test-dir build --output-on-failure

  # ==========================================================================
  # Static Analysis
  # ==========================================================================
  static-analysis:
    name: Static Analysis (clang-tidy)
    runs-on: ubuntu-latest
    container: rootproject/root:latest

    steps:
      - uses: actions/checkout@v4

      - name: Install clang-tidy (and Ninja + OpenMP headers)
        run: |
          apt-get update
          apt-get install -y --no-install-recommends \
            cmake ninja-build \
            clang clang-tidy libomp-dev

      - name: Configure (Clang compile database)
        run: |
          CC=clang CXX=clang++ cmake -B build -G Ninja \
            -DCMAKE_BUILD_TYPE=Debug \
            -DCMAKE_EXPORT_COMPILE_COMMANDS=ON

      - name: Run clang-tidy (fail on errors)
        run: |
          find src include \( -name '*.cpp' -o -name '*.hpp' \) -print0 | \
          xargs -0 -r clang-tidy -p build --warnings-as-errors='*'

  # ==========================================================================
  # Benchmarks (on main only)
  # ==========================================================================
  benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    container: rootproject/root:latest
    if: github.ref == 'refs/heads/main'
    needs: build

    steps:
      - uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          apt-get update
          apt-get install -y --no-install-recommends \
            cmake ninja-build python3 python3-pip
          pip3 install --break-system-packages matplotlib

      - name: Configure
        run: |
          cmake -B build -G Ninja \
            -DCMAKE_BUILD_TYPE=Release \
            -DBUILD_BENCHMARKS=ON

      - name: Build
        run: cmake --build build -j"$(nproc)"

      - name: Run Benchmarks
        run: |
          ./build/benchmarks \
            --benchmark_format=json \
            --benchmark_out=benchmark_results.json

      - name: Generate Benchmark Report (log)
        run: |
          python3 << 'EOF'
          import json
          with open('benchmark_results.json') as f:
              data = json.load(f)

          print("# Benchmark Results\n")
          print("| Benchmark | Time (ns) | CPU (ns) | Iterations |")
          print("|-----------|-----------|----------|------------|")
          for bench in data.get('benchmarks', []):
              name = bench.get('name', 'N/A')
              time = bench.get('real_time', 0.0)
              cpu = bench.get('cpu_time', 0.0)
              iters = bench.get('iterations', 0)
              print(f"| {name} | {time:.2f} | {cpu:.2f} | {iters} |")
          EOF

      - name: Upload Benchmark Results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark_results.json
          retention-days: 30

  # ==========================================================================
  # Documentation (optional, main only)
  # ==========================================================================
  docs:
    name: Build Documentation
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && hashFiles('mkdocs.yml') != ''

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install mkdocs
        run: pip install mkdocs mkdocs-material

      - name: Build docs
        run: mkdocs build -d site

      - name: Upload docs artifact
        uses: actions/upload-artifact@v4
        with:
          name: documentation
          path: site/
          retention-days: 7
